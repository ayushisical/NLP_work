{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSTFXFSLzZxF"
      },
      "source": [
        "\n",
        "# basics\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import collections\n",
        "\n",
        "# visualization\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# tools\n",
        "import scipy\n",
        "import math\n",
        "import random\n",
        "import sklearn\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTe3nWPmqMjt"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zihz7r9OqUbT"
      },
      "source": [
        "finalbooks=pd.read_csv(\"\")\n",
        "ratings= pd.read_csv(\"\")\n",
        "test=pd.read_csv(\"\")\n",
        "train= pd.read_csv(\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHIG3a1GqMgq"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXWR0-T1zlRs"
      },
      "source": [
        "## NDGC & RMSE\n",
        "\n",
        "def dcg_k(r, k):\n",
        "    \"\"\" Discounted Cumulative Gain (DGC)\n",
        "    Args:\n",
        "        r: True Ratings in Predicted Rank Order (1st element is top recommendation)\n",
        "        k: Number of results to consider\n",
        "    Returns:\n",
        "        DCG\n",
        "    \"\"\"\n",
        "\n",
        "    r = np.asfarray(r)[:k]\n",
        "    return np.sum(2**r / np.log2(np.arange(2, r.size + 2)))\n",
        "\n",
        "\n",
        "\n",
        "def ndcg_k(r, k):\n",
        "    \"\"\"Normalized Discounted Cumulative Gain (NDCG)\n",
        "    Args:\n",
        "        r: True Ratings in Predicted Rank Order (1st element is top recommendation)\n",
        "        k: Number of results to consider\n",
        "    Returns:\n",
        "        NDCG\n",
        "    \"\"\"\n",
        "    dcg_max = dcg_k(sorted(r, reverse=True), k)\n",
        "    if not dcg_max:\n",
        "        return 0.\n",
        "    return dcg_k(r, k) / dcg_max\n",
        "\n",
        "def mean_ndcg(rs):\n",
        "    \"\"\"Mean NDCG for all users\n",
        "    Args:\n",
        "        rs: Iterator / For each user: True Ratings in Predicted Rank Order\n",
        "    Returns:\n",
        "        Mean NDCG\n",
        "    \"\"\"\n",
        "    return np.mean([ndcg_k(r, len(r)) for r in rs])\n",
        "\n",
        "def rmse(y,h):\n",
        "    \"\"\"RMSE\n",
        "    Args:\n",
        "        y: real y\n",
        "        h: predicted y\n",
        "    Returns:\n",
        "        RMSE\n",
        "    \"\"\"\n",
        "    a = y-h\n",
        "\n",
        "    return np.sqrt(sum(a**2)/len(a))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SI_IdnBnzoeE"
      },
      "source": [
        "## DEFINING THE TAIL\n",
        "tailcomp = ratings.groupby(by= 'newbookid', as_index=False).agg({'rating':pd.Series.count}).sort_values(by = 'rating', ascending = False)\n",
        "tot = sum(tailcomp['rating'])\n",
        "tailcomp['popshare']= [x/tot for x in tailcomp['rating']]\n",
        "tailcomp['popshare']= tailcomp['popshare'].cumsum()\n",
        "tailcomp['category']= ['Head' if x<0.95 else \"Tail\" for x in tailcomp['popshare']]\n",
        "\n",
        "tail = tailcomp.loc[tailcomp.popshare >= 0.95]\n",
        "tail"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21u2436wzuGs"
      },
      "source": [
        "def get_words(message):\n",
        "    \"\"\"Get the normalized list of words from a message string.\n",
        "\n",
        "    This function should split a message into words, normalize them, and return\n",
        "    the resulting list. For splitting, you should split on spaces. For normalization,\n",
        "    you should convert everything to lowercase.\n",
        "\n",
        "    Args:\n",
        "        message: A string containing an SMS message\n",
        "\n",
        "    Returns:\n",
        "       The list of normalized words from the message.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    words = message\n",
        "    words = words.split(\" \")\n",
        "    words = [x.lower() for x in words]\n",
        "\n",
        "    return words\n",
        "\n",
        "\n",
        "\n",
        "def create_dictionary(messages):\n",
        "    \"\"\"Create a dictionary mapping words to integer indices.\n",
        "\n",
        "    Args:\n",
        "        messages: A list of strings containing SMS messages\n",
        "\n",
        "    Returns:\n",
        "        A python dict mapping words to integers.\n",
        "    \"\"\"\n",
        "\n",
        "    word_counts = collections.defaultdict(int)\n",
        "\n",
        "    for message in messages:\n",
        "        for word in set(get_words(message)):\n",
        "            word_counts[word] += 1\n",
        "\n",
        "    resulting_dictionary = {}\n",
        "\n",
        "    for word, count in word_counts.items():\n",
        "        if count >= 10 and word not in stopwords.words('english') and len(word) > 1:\n",
        "            next_index = len(resulting_dictionary)\n",
        "            resulting_dictionary[word] = next_index\n",
        "\n",
        "    return resulting_dictionary\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def transform_text(messages, word_dictionary):\n",
        "    \"\"\"Transform a list of text messages into a numpy array for further processing.\n",
        "\n",
        "    Args:\n",
        "        messages: A list of strings where each string is an SMS message.\n",
        "        word_dictionary: A python dict mapping words to integers.\n",
        "\n",
        "    Returns:\n",
        "        A numpy array marking the words present in each message.\n",
        "        Where the component (i,j) is the number of occurrences of the\n",
        "        j-th vocabulary word in the i-th message.\n",
        "    \"\"\"\n",
        "\n",
        "    A = np.zeros((len(messages), len(word_dictionary)))\n",
        "\n",
        "    for i, message in enumerate(messages):\n",
        "        for word in get_words(message):\n",
        "            if word in word_dictionary:\n",
        "                A[i, word_dictionary[word]] += 1\n",
        "\n",
        "    return A\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfwnJrgVUraP"
      },
      "source": [
        "finalbooks['snippet'] = finalbooks['snippet'].fillna(finalbooks['title'])\n",
        "finalbooks['snippet'] = finalbooks['snippet'].str.replace(r'[^\\w\\s]',\"\")\n",
        "finalbooks['snippet'] = finalbooks['snippet'].str.replace('-',\"\")\n",
        "finalbooks['tag_cloud'] = finalbooks['tag_cloud'].str.replace('-',\" \")\n",
        "finalbooks['snippet'] = finalbooks['snippet'].fillna(finalbooks['tag_cloud'])\n",
        "finalbooks['words'] = finalbooks['snippet'] +\" \"+finalbooks['tag_cloud']+\" \"+finalbooks['first_author']\n",
        "dico = create_dictionary(finalbooks['words'])\n",
        "dico"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_102qoWwZCDb"
      },
      "source": [
        "len(dico)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2g84nGSUz47"
      },
      "source": [
        "A = transform_text(finalbooks['words'], dico)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbxYKZhAZGuf"
      },
      "source": [
        "np.size(A, 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2KOcXWMaCPW"
      },
      "source": [
        "np.sum(A, axis=1).min()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUKKlE1tX9Nl"
      },
      "source": [
        "\n",
        "A1 = np.sum((A>0), axis= 0)\n",
        "\n",
        "IDF = np.log(np.size(A, 0)/A1)\n",
        "IDF\n",
        "len(IDF)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30l715jZYSfO"
      },
      "source": [
        "TF = A / (np.sum(A, axis=1, keepdims=True))\n",
        "np.shape(TF)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIMmKTCkbz2W"
      },
      "source": [
        "TFiDF= TF*IDF\n",
        "np.shape(TFiDF)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCU-Z0ZDdTel"
      },
      "source": [
        "#ids = np.argsort(TFiDF.mean(axis=1))[:5]\n",
        "#reverse_dictionary = {i: word for word, i in dico.items()}\n",
        "#[reverse_dictionary[i] for i in ids]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CCS9A3ld2MY"
      },
      "source": [
        "TFiDF = TFiDF / np.sqrt((np.sum(TFiDF**2, axis = 1, keepdims=True)+0.01))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9rRbnhQeBWL"
      },
      "source": [
        "SimC = np.dot(TFiDF, TFiDF.T)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAob-weGfxpO"
      },
      "source": [
        "SimC"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEptdwFH12up"
      },
      "source": [
        "np.sum(SimC, axis = 1).max()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_PyUVHV1-D7"
      },
      "source": [
        "np.fill_diagonal(SimC, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzSByLFd_ik0"
      },
      "source": [
        "SimC"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTe47C-2iKwD"
      },
      "source": [
        "BookSim =pd.DataFrame(SimC, columns=finalbooks.title, index=finalbooks.title)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nabTzZElmmg"
      },
      "source": [
        "\n",
        "#np.argsort(SimC[53, :])[-5:]\n",
        "finalbooks.title[np.argsort(SimC[15, :])[-6:]]\n",
        "#Sim20 = pd.DataFrame(Sim20, columns=finalbooks.title[101:200], index=finalbooks.title[50:60])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJunZhEsRqcR"
      },
      "source": [
        "SimC[15, [15, 2252, 6977, 4642, 2796, 1700 ]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XUtH99nORAF"
      },
      "source": [
        "finalbooks [finalbooks.newbookid.isin(np.argsort(SimC[15, :])[-6:]+1)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBKH8K6okYwU"
      },
      "source": [
        "# Set up the matplotlib figure\n",
        "f, ax = plt.subplots(figsize=(27.5, 22.5))\n",
        "\n",
        "# Generate a custom diverging colormap followed by the correlation heatmap\n",
        "cmap =sns.diverging_palette(20, 220, n=20000)\n",
        "\n",
        "sns.heatmap(BookSim, cmap=cmap,center = 0,\n",
        "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZ3WAXB-0I7d"
      },
      "source": [
        "train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hhh3kxj90UPZ"
      },
      "source": [
        "allpreds = []\n",
        "train = train.sort_values(by=['newbookid'])\n",
        "for i in range(15000):\n",
        "  bi = train.newbookid[train.newuser_id == i+1]-1\n",
        "  Simi = SimC[:, bi]\n",
        "  ri = np.array(train[train.newuser_id == i+1].sort_values(by=['newbookid']).rating)\n",
        "  predi = finalbooks.filter(['newbookid'])\n",
        "  predi['pred'] = np.sum(Simi*ri, axis=1)/(np.sum(Simi, axis=1)+0.01)\n",
        "  predi['newuser_id'] = i+1\n",
        "  allpreds.append(predi)\n",
        "  if (i+1)%1000 == 0: print(\"done: \", i+1)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8B5kWb112Xo4"
      },
      "source": [
        "predictions = np.concatenate(allpreds, axis=0 )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-JbC34N3mYc"
      },
      "source": [
        "final =pd.DataFrame(predictions, columns=['newbookid', 'pred', 'newuser_id'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BR18POhP7Qx-"
      },
      "source": [
        "train['conc']=train['newuser_id'].map(str)+train['newbookid'].map(str)\n",
        "final['conc']=final['newuser_id'].map(str)+final['newbookid'].map(str)\n",
        "finalfin = final[~final.conc.isin(train.conc)]\n",
        "finalfin.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYuqO7pT9VjI"
      },
      "source": [
        "finalrank = test.merge(final,on = ['newbookid', 'newuser_id'])\n",
        "finalrank = finalrank.sort_values(by=['newuser_id', 'pred'], ascending=False)\n",
        "finalrank.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2cerIHF7WmE"
      },
      "source": [
        "finallist = []\n",
        "for i in range(15000):\n",
        "    a = finalrank.loc[finalrank.newuser_id == i+1]['rating'].tolist()\n",
        "    finallist.append(a)\n",
        "    if (i+1)%1000 == 0: print(\"done: \", i+1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaYc72SA7ZNr"
      },
      "source": [
        "b = np.array([ndcg_k(r, len(r)) for r in finallist])\n",
        "\n",
        "\n",
        "facet, axes = plt.subplots(1, 1, figsize=(10, 3))\n",
        "n, bins, patches = plt.hist(b, 200, facecolor='blue', alpha=0.5) #, log = True)\n",
        "plt.title('Distribution of NDGC among Users for the TFiDF model')\n",
        "plt.show()\n",
        "\n",
        "# [ndcg_k(r, len(r)) for r in poplista]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlRMRek_jt4z"
      },
      "source": [
        "d = b[b == 1]\n",
        "sum(d)/15000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7YCZVT37b5h"
      },
      "source": [
        "top10 = finalfin.sort_values('pred',ascending = False).groupby('newuser_id').head(10)\n",
        "top50 = finalfin.sort_values('pred',ascending = False).groupby('newuser_id').head(50)\n",
        "\n",
        "print('(1) TF-iDF Model RMSE: ', np.round(rmse(finalrank['pred'],finalrank['rating']), decimals=3))\n",
        "print('(2) TF-iDF Model NDCG: ', np.round(mean_ndcg(finallist), decimals=3))\n",
        "print(\"(2) Median NDCG: \", np.round(np.median(b), decimals=3))\n",
        "print(\"(2) Share of NDCG =1 among Users: \", np.round(sum(d)/15000, decimals=3))\n",
        "print('(3) TF-iDF Model Div10 Score: ',np.round(sum(np.in1d(top10.newbookid, tail.newbookid))/len(top10), decimals=3))\n",
        "print('(3) TF-iDF Model Div50 Score: ',np.round(sum(np.in1d(top50.newbookid, tail.newbookid))/len(top50), decimals=3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0z53UQ5txM6R"
      },
      "source": [
        "finalranktrain = train.merge(final,on = ['newbookid', 'newuser_id'])\n",
        "finalranktrain = finalranktrain.sort_values(by=['newuser_id', 'pred'], ascending=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6w_1TMmd__UW"
      },
      "source": [
        "finalranktrain"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSqkxSJtxVTp"
      },
      "source": [
        "finallisttrain = []\n",
        "for i in range(15000):\n",
        "    a = finalranktrain.loc[finalranktrain.newuser_id == i+1]['rating'].tolist()\n",
        "    finallisttrain.append(a)\n",
        "    if (i+1)%1000 == 0: print(\"done: \", i+1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXGR11u0xfat"
      },
      "source": [
        "print('(1) TF-iDF Train Model RMSE: ', np.round(rmse(finalranktrain['pred'],finalranktrain['rating']), decimals=3))\n",
        "print('(2) TF-iDF Train Model NDCG: ', np.round(mean_ndcg(finallisttrain), decimals=3))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}