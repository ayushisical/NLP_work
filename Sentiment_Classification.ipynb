{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6wxwN7m6YLR"
      },
      "source": [
        "# Sentiment Classification with IMDB Data\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yK4V01r16YLV"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMDM-OjL6YLV"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "\n",
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import scipy\n",
        "from PIL import Image\n",
        "from scipy import ndimage\n",
        "\n",
        "max_features = 5000  # Only consider the top 5k words\n",
        "maxlen = 200  # Only consider the first 200 words of each movie review\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9V6pCBl6YLX"
      },
      "source": [
        "## Load the IMDB movie review sentiment data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtCx5GFn6YLY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f576822c-f5f4-457f-bd32-34fd2a45de14"
      },
      "source": [
        "(x_train_orig, y_train_orig), (x_val_orig, y_val_orig) = keras.datasets.imdb.load_data(\n",
        "    num_words=max_features\n",
        ")\n",
        "print(len(x_train_orig), \"Training sequences\")\n",
        "print(len(x_val_orig), \"Validation sequences\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n",
            "17473536/17464789 [==============================] - 0s 0us/step\n",
            "25000 Training sequences\n",
            "25000 Validation sequences\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imZ3iT-VUzaR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3460b1e-3d2b-4164-f24b-eba7ccb96f48"
      },
      "source": [
        "print(x_train_orig.shape, y_train_orig.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(25000,) (25000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrgnsFPtIg8r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53baef76-707c-46e9-800f-0d6c27345bc6"
      },
      "source": [
        "# Retrieve the word index file mapping words to indices\n",
        "word_index = keras.datasets.imdb.get_word_index()\n",
        "# Reverse the word index to obtain a dict mapping indices to words\n",
        "inverted_word_index = dict((i, word) for (word, i) in word_index.items())\n",
        "# Example: decode the first sequence in the dataset\n",
        "decoded_sequence = \" \".join(inverted_word_index[i] for i in x_train_orig[0])\n",
        "print(decoded_sequence)\n",
        "print(y_train_orig[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 0s 0us/step\n",
            "1654784/1641221 [==============================] - 0s 0us/step\n",
            "the as you with out themselves powerful lets loves their becomes reaching had journalist of lot from anyone to have after out atmosphere never more room and it so heart shows to years of every never going and help moments or of every chest visual movie except her was several of enough more with is now current film as you of mine potentially unfortunately of you than him that with out themselves her get for was camp of you movie sometimes movie that with scary but and to story wonderful that in seeing in character to of 70s and with heart had shadows they of here that with her serious to have does when from why what have critics they is you that isn't one will very to as itself with other and in of seen over and for anyone of and br show's to whether from than out themselves history he name half some br of and odd was two most of mean for 1 any an boat she he should is thought and but of script you not while history he heart to real at and but when from one bit then have two of script their with her nobody most that with wasn't to with armed acting watch an for with and film want an\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJ_unNl8Czxm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "850be881-4eda-4772-c5a2-b91b38c629bd"
      },
      "source": [
        "print(x_train_orig[0][:])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 2, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 2, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 2, 19, 178, 32]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUKu858lIv49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0da2787c-5bb6-4af3-8872-4c45efc6f6ab"
      },
      "source": [
        "x_train = keras.preprocessing.sequence.pad_sequences(x_train_orig, maxlen=maxlen)\n",
        "x_val = keras.preprocessing.sequence.pad_sequences(x_val_orig, maxlen=maxlen)\n",
        "\n",
        "print(x_train.shape, x_val.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(25000, 200) (25000, 200)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVlIZslRUmmC"
      },
      "source": [
        "print(y_train_orig.shape)\n",
        "print(y_val_orig.shape)\n",
        "y_train_cat = keras.utils.to_categorical(y_train_orig, num_classes=2)\n",
        "y_val_cat = keras.utils.to_categorical(y_val_orig, num_classes=2)\n",
        "\n",
        "print(y_train_cat.shape)\n",
        "print(y_val_cat.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6UtMcWfL3_v"
      },
      "source": [
        "print(x_train[2,:])\n",
        "print(y_train_cat[2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyyDk0g16YLY"
      },
      "source": [
        "## Train and evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBFgQVROVRvv"
      },
      "source": [
        "max_features = 5000\n",
        "inputs = keras.Input(shape=(None,), dtype=\"int32\")\n",
        "x = keras.layers.Embedding(max_features,\n",
        "                           256,\n",
        "                           embeddings_initializer=keras.initializers.Identity(gain=0.5),\n",
        "                           trainable=True)(inputs)\n",
        "x = keras.layers.SimpleRNN(32)(x)\n",
        "outputs = keras.layers.Dense(1, activation='sigmoid')(x)\n",
        "model0 = keras.Model(inputs, outputs)\n",
        "model0.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qt3OZknQC3hy"
      },
      "source": [
        "# Input for variable-length sequences of integers\n",
        "inputs = keras.Input(shape=(None,), dtype=\"int32\")\n",
        "# Embed each integer in a 128-dimensional vector\n",
        "x = keras.layers.Embedding(max_features, 128)(inputs)\n",
        "# Add a simpleRNN layer\n",
        "x = keras.layers.SimpleRNN(64)(x)\n",
        "# Add a classifier\n",
        "outputs = keras.layers.Dense(2, activation=\"softmax\")(x)\n",
        "model1 = keras.Model(inputs, outputs)\n",
        "model1.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use BinaryCrossEntropy when $y \\in \\{0,1\\}$. If $y$ is a two dimensional vector with one of the entries 1, then use CategoricalCrossEntropy. Use the y_train and y_val accordingly."
      ],
      "metadata": {
        "id": "J-2dmA_1ITeT"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXUx_Xg3cY0l"
      },
      "source": [
        "def train_model(model, epochs):\n",
        "  #optimizer = keras.optimizers.SGD(learning_rate=0.1)\n",
        "  optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
        "  bce = keras.losses.BinaryCrossentropy(from_logits=False)\n",
        "  # cce = keras.losses.CategoricalCrossentropy()\n",
        "  model.compile(optimizer=optimizer,\n",
        "              loss=cce,\n",
        "              # loss=bce,\n",
        "              metrics=['accuracy'])\n",
        "  return model.fit(x_train, y_train_orig, batch_size=256, epochs=epochs, validation_data=(x_val, y_val_orig))\n",
        "\n",
        "def plot_training(trained_model, epochs):\n",
        "  # Print the learning curve\n",
        "  plt.plot(range(1, epochs+1), trained_model.history['loss'] , 'r', range(1, epochs+1), trained_model.history['val_loss'], 'b')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Loss')\n",
        "  _ = plt.legend(['Training Loss', 'Validation Loss'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZDXIzTXSqXw"
      },
      "source": [
        "trained_model1 = train_model(model1, 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GfJy3LCEWUV"
      },
      "source": [
        "plot_training(trained_model1, 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6ORb-WZmc6H"
      },
      "source": [
        "# Input for variable-length sequences of integers\n",
        "inputs = keras.Input(shape=(None,), dtype=\"int32\")\n",
        "# Embed each integer in a 128-dimensional vector\n",
        "x = keras.layers.Embedding(max_features, 128)(inputs)\n",
        "# Add 2 bidirectional LSTMs\n",
        "x = keras.layers.Bidirectional(keras.layers.LSTM(64, return_sequences=True))(x)\n",
        "x = keras.layers.Bidirectional(keras.layers.LSTM(64))(x)\n",
        "# Add a classifier\n",
        "outputs = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model2 = keras.Model(inputs, outputs)\n",
        "model2.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FN9qAnPB8oJF"
      },
      "source": [
        "trained_model2 = train_model(model2, 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2xib28LGE1E"
      },
      "source": [
        "plot_training(trained_model2, 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-9gsujZGcKB"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}